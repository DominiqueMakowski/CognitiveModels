[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Cognitive Models",
    "section": "",
    "text": "Preface\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "1_introduction.html",
    "href": "1_introduction.html",
    "title": "1  Pieces of Puzzle",
    "section": "",
    "text": "Very quick intro to Julia and Turing\n\n\n\nCode\nusing Plots\n\nplot(1:10)\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Regression: understand what the parameters mean (intercept, slopes, sigma)\nBoostrapping: Introduce concepts related to pseudo-posterior distribution description\nHierarchical Models: Simpson’s paradox, random effects, how to leverage them to model interindividual differences\nBayesian estimation: introduce Bayesian estimation and priors over parameters\nBayesian mixed linear regression: put everything together",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pieces of Puzzle</span>"
    ]
  },
  {
    "objectID": "2_predictors.html",
    "href": "2_predictors.html",
    "title": "2  Predictors",
    "section": "",
    "text": "2.1 Categorical predictors (Condition, Group, …)\nNested interactions, contrasts, …",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Predictors</span>"
    ]
  },
  {
    "objectID": "2_predictors.html#ordered-predictors-likert-scales",
    "href": "2_predictors.html#ordered-predictors-likert-scales",
    "title": "2  Predictors",
    "section": "2.2 Ordered predictors (Likert Scales)",
    "text": "2.2 Ordered predictors (Likert Scales)\nLikert scales, i.e., ordered multiple discrete choices are often used in surveys and questionnaires. While such data is often treated as a continuous variable, such assumption is not necessarily valid. Indeed, distance between the choices is not necessarily equal. For example, the difference between “strongly agree” and “agree” might not be the same as between “agree” and “neutral”. Even when using integers like 1, 2, 3, 4; people might implicitly process “4” as more extreme relative to “3” as “3” to “2”.\n\n\nThe probabilities assigned to discrete probability descriptors are not necessarily equidistant (https://github.com/zonination/perceptions)\n\nWhat can we do to better reflect the cognitive process underlying a Likert scale responses? Monotonic effects.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Predictors</span>"
    ]
  },
  {
    "objectID": "2_predictors.html#interactions",
    "href": "2_predictors.html#interactions",
    "title": "2  Predictors",
    "section": "2.3 Interactions",
    "text": "2.3 Interactions\nTodo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Predictors</span>"
    ]
  },
  {
    "objectID": "2_predictors.html#non-linear-relationships-polynomial-gams",
    "href": "2_predictors.html#non-linear-relationships-polynomial-gams",
    "title": "2  Predictors",
    "section": "2.4 Non-linear relationships (polynomial, GAMs)",
    "text": "2.4 Non-linear relationships (polynomial, GAMs)\nTodo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Predictors</span>"
    ]
  },
  {
    "objectID": "3_scales.html",
    "href": "3_scales.html",
    "title": "3  Choice and Scales",
    "section": "",
    "text": "Logistic models for binary data\nBeta models\nOrdBeta models for slider scales",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Choice and Scales</span>"
    ]
  },
  {
    "objectID": "4_rt.html",
    "href": "4_rt.html",
    "title": "4  Reaction Times",
    "section": "",
    "text": "4.1 The Data\nData from Wagenmakers et al. (2008) - Experiment 1. We excluded all trials with uninterpretable response time (see Thériault et al. 2024) such as too fast response (&lt;180 ms) and too slow response (&gt;2 sec).\nusing Downloads, CSV, DataFrames\nusing Turing, Distributions, SequentialSamplingModels\nusing CairoMakie\n\ndf = CSV.read(Downloads.download(\"https://raw.githubusercontent.com/DominiqueMakowski/CognitiveModels/main/data/wagenmakers2008.csv\"), DataFrame)\nfirst(df, 10)\n\n10×5 DataFrame\n\n\n\nRow\nParticipant\nCondition\nRT\nError\nFrequency\n\n\n\nInt64\nString15\nFloat64\nBool\nString15\n\n\n\n\n1\n1\nSpeed\n0.7\nfalse\nLow\n\n\n2\n1\nSpeed\n0.392\ntrue\nVery Low\n\n\n3\n1\nSpeed\n0.46\nfalse\nVery Low\n\n\n4\n1\nSpeed\n0.455\nfalse\nVery Low\n\n\n5\n1\nSpeed\n0.505\ntrue\nLow\n\n\n6\n1\nSpeed\n0.773\nfalse\nHigh\n\n\n7\n1\nSpeed\n0.39\nfalse\nHigh\n\n\n8\n1\nSpeed\n0.587\ntrue\nLow\n\n\n9\n1\nSpeed\n0.603\nfalse\nLow\n\n\n10\n1\nSpeed\n0.435\nfalse\nHigh\nWe create a new column, Accuracy, which is the “binarization” of the Condition column, and is equal to 1 when the condition is \"Accuracy\" and 0 when it is \"Speed\".\nCode\ndf = df[df.Error .== 0, :]\ndf.Accuracy = df.Condition .== \"Accuracy\"\nCode\nfunction plot_distribution(df, title=\"Empirical Distribution of Data from Wagenmakers et al. (2018)\")\n    fig = Figure()\n    ax = Axis(fig[1, 1], title=title,\n        xlabel=\"RT (s)\",\n        ylabel=\"Distribution\",\n        yticksvisible=false,\n        xticksvisible=false,\n        yticklabelsvisible=false)\n    CairoMakie.density!(df[df.Condition .== \"Speed\", :RT], color=(\"#EF5350\", 0.7), label = \"Speed\")\n    CairoMakie.density!(df[df.Condition .== \"Accuracy\", :RT], color=(\"#66BB6A\", 0.7), label = \"Accuracy\")\n    CairoMakie.axislegend(\"Condition\"; position=:rt)\n    CairoMakie.ylims!(ax, (0, nothing))\n    return fig\nend\n\nplot_distribution(df, \"Empirical Distribution of Data from Wagenmakers et al. (2018)\")\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n└ @ Makie C:\\Users\\domma\\.julia\\packages\\Makie\\VRavR\\src\\scenes.jl:220",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reaction Times</span>"
    ]
  },
  {
    "objectID": "4_rt.html#the-data",
    "href": "4_rt.html#the-data",
    "title": "4  Reaction Times",
    "section": "",
    "text": "Code Tip\n\n\n\nNote the usage of vectorization .== as we want to compare each element of the Condition vector to the target \"Accuracy\".",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reaction Times</span>"
    ]
  },
  {
    "objectID": "4_rt.html#descriptive-models-exgaussian-lognormal-wald",
    "href": "4_rt.html#descriptive-models-exgaussian-lognormal-wald",
    "title": "4  Reaction Times",
    "section": "4.2 Descriptive Models (ExGaussian, LogNormal, Wald)",
    "text": "4.2 Descriptive Models (ExGaussian, LogNormal, Wald)\n\n4.2.1 Modelling RT with a Bayesian Linear Model\n\n4.2.1.1 The Data\n\n\n4.2.1.2 The Model\n\n@model function model_linear(rt; condition=nothing)\n\n    # Set priors on variance, intercept and effect of ISI\n    σ² ~ truncated(Normal(0, 1); lower=0)\n    intercept ~ truncated(Normal(0, 1); lower=0)\n    slope_accuracy ~ Normal(0, 0.5)\n\n    for i in 1:length(rt)\n        μ = intercept + slope_accuracy * condition[i]\n        rt[i] ~ Normal(μ, σ²)\n    end\nend\n\n\nmodel = model_linear(df.RT, condition=df.Accuracy)\nchain_linear = sample(model, NUTS(), 200)\n\n# Summary (95% CI)\nquantile(chain_linear; q=[0.025, 0.975])\n\n┌ Info: Found initial step size\n└   ϵ = 0.00625\nSampling:   0%|█                                        |  ETA: 0:01:00Sampling: 100%|█████████████████████████████████████████| Time: 0:00:01\n\n\n\nQuantiles\n      parameters      2.5%     97.5% \n          Symbol   Float64   Float64 \n              σ²    0.1651    0.1699\n       intercept    0.5072    0.5166\n  slope_accuracy    0.1327    0.1451\n\n\n\n\nThe effect of Condition is significant, people are on average slower (higher RT) when condition is \"Accuracy\". But is our model good?\n\n\n4.2.1.3 Posterior Predictive Check\n\n\nCode\npred = predict(model_linear([(missing) for i in 1:length(df.RT)], condition=df.Accuracy), chain_linear)\npred = Array(pred)\n\n\n\n\nCode\nfig = plot_distribution(df, \"Predictions made by Linear Model\")\nfor i in 1:length(chain_linear)\n    lines!(Makie.KernelDensity.kde(pred[:, i]), color=ifelse(df.Accuracy[i] == 1, \"#388E3C\", \"#D32F2F\"), alpha=0.1)\nend\nfig\n\n\n┌ Warning: Found `resolution` in the theme when creating a `Scene`. The `resolution` keyword for `Scene`s and `Figure`s has been deprecated. Use `Figure(; size = ...` or `Scene(; size = ...)` instead, which better reflects that this is a unitless size and not a pixel resolution. The key could also come from `set_theme!` calls or related theming functions.\n└ @ Makie C:\\Users\\domma\\.julia\\packages\\Makie\\VRavR\\src\\scenes.jl:220\n\n\n\n\n\n\n\n\n\n\n\n4.2.1.4 The Problem with Linear Models\nReaction time (RTs) have been traditionally modeled using traditional linear models and their derived statistical tests such as t-test and ANOVAs. Importantly, linear models - by definition - will try to predict the mean of the outcome variable by estimating the “best fitting” Normal distribution. In the context of reaction times (RTs), this is not ideal, as RTs typically exhibit a non-normal distribution, skewed towards the left with a long tail towards the right. This means that the parameters of a Normal distribution (mean \\(\\mu\\) and standard deviation \\(\\sigma\\)) are not good descriptors of the data.\n\n\nLinear models try to find the best fitting Normal distribution for the data. However, for reaction times, even the best fitting Normal distribution (in red) does not capture well the actual data (in grey).\n\nA popular mitigation method to account for the non-normality of RTs is to transform the data, using for instance the popular log-transform. However, this practice should be avoided as it leads to various issues, including loss of power and distorted results interpretation (Lo and Andrews 2015; Schramm and Rouder 2019). Instead, rather than applying arbitrary data transformation, it would be better to swap the Normal distribution used by the model for a more appropriate one that can better capture the characteristics of a RT distribution.\n\n\n\n4.2.2 Shifted LogNormal Model\nOne of the obvious candidate alternative to the log-transformation would be to use a model with a Log-transformed Normal distribution.\n\n\n4.2.3 ExGaussian Model\n\n\n4.2.4 Wald Model\nMoe from statistical models that describe to models that generate RT-like data.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reaction Times</span>"
    ]
  },
  {
    "objectID": "4_rt.html#generative-models-ddm",
    "href": "4_rt.html#generative-models-ddm",
    "title": "4  Reaction Times",
    "section": "4.3 Generative Models (DDM)",
    "text": "4.3 Generative Models (DDM)\nUse DDM as a case study to introduce generative models",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reaction Times</span>"
    ]
  },
  {
    "objectID": "4_rt.html#other-models-lba-lnr",
    "href": "4_rt.html#other-models-lba-lnr",
    "title": "4  Reaction Times",
    "section": "4.4 Other Models (LBA, LNR)",
    "text": "4.4 Other Models (LBA, LNR)",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reaction Times</span>"
    ]
  },
  {
    "objectID": "4_rt.html#additional-resources",
    "href": "4_rt.html#additional-resources",
    "title": "4  Reaction Times",
    "section": "4.5 Additional Resources",
    "text": "4.5 Additional Resources\n\nLindelov’s overview of RT models: An absolute must-read.\nDe Boeck & Jeon (2019): A paper providing an overview of RT models.\nhttps://github.com/vasishth/bayescogsci\n\n\n\n\n\nLo, Steson, and Sally Andrews. 2015. “To Transform or Not to Transform: Using Generalized Linear Mixed Models to Analyse Reaction Time Data.” Frontiers in Psychology 6: 1171.\n\n\nSchramm, Pele, and Jeffrey N Rouder. 2019. “Are Reaction Time Transformations Really Beneficial?”\n\n\nThériault, Rémi, Mattan S Ben-Shachar, Indrajeet Patil, Daniel Lüdecke, Brenton M Wiernik, and Dominique Makowski. 2024. “Check Your Outliers! An Introduction to Identifying Statistical Outliers in r with Easystats.” Behavior Research Methods 56 (4): 4162–72.\n\n\nWagenmakers, Eric-Jan, Roger Ratcliff, Pablo Gomez, and Gail McKoon. 2008. “A Diffusion Model Account of Criterion Shifts in the Lexical Decision Task.” Journal of Memory and Language 58 (1): 140–59.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Reaction Times</span>"
    ]
  },
  {
    "objectID": "5_individual.html",
    "href": "5_individual.html",
    "title": "5  Individual Parameters",
    "section": "",
    "text": "From mixed models\nAs prior-informed individual Bayesian models",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Individual Parameters</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Lo, Steson, and Sally Andrews. 2015. “To Transform or Not to\nTransform: Using Generalized Linear Mixed Models to Analyse Reaction\nTime Data.” Frontiers in Psychology 6: 1171.\n\n\nSchramm, Pele, and Jeffrey N Rouder. 2019. “Are Reaction Time\nTransformations Really Beneficial?”\n\n\nThériault, Rémi, Mattan S Ben-Shachar, Indrajeet Patil, Daniel Lüdecke,\nBrenton M Wiernik, and Dominique Makowski. 2024. “Check Your\nOutliers! An Introduction to Identifying Statistical Outliers in r with\nEasystats.” Behavior Research Methods 56 (4): 4162–72.\n\n\nWagenmakers, Eric-Jan, Roger Ratcliff, Pablo Gomez, and Gail McKoon.\n2008. “A Diffusion Model Account of Criterion Shifts in the\nLexical Decision Task.” Journal of Memory and Language\n58 (1): 140–59.",
    "crumbs": [
      "References"
    ]
  }
]