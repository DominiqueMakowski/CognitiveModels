# Fundamentals of Bayesian Modeling in Julia

![](https://img.shields.io/badge/status-not_started-red)


## Very quick intro to Julia and Turing

Goal is to teach just enough so that the reader understands the code.

### Generate Data from Normal Distribution

```{julia}
#| output: false
using Turing, Distributions, Random
using Makie

# Random sample from a Normal(μ=100, σ=15)
iq = rand(Normal(100, 15), 500)
```

```{julia}
fig = Figure()
ax = Axis(fig[1, 1], title="Distribution")
density!(ax, iq)
fig
```

### Recover Distribution Parameters with Turing

```{julia}
@model function model_gaussian(x)
    # Priors
    μ ~ Uniform(0, 200)
    σ ~ Uniform(0, 30)

    # Check against each datapoint
    for i in 1:length(x)
        x[i] ~ Normal(μ, σ)
    end
end

model = model_gaussian(iq)
sampling_results = sample(model, NUTS(), 400)

# Summary (95% CI)
summarystats(sampling_results)
```


## Linear Models

Understand what the parameters mean (intercept, slopes, sigma).

## Boostrapping

Introduce concepts related to pseudo-posterior distribution description

## Hierarchical Models

Simpson's paradox, random effects, how to leverage them to model interindividual differences

## Bayesian estimation

introduce Bayesian estimation and priors over parameters

## Bayesian mixed linear regression

put everything together
